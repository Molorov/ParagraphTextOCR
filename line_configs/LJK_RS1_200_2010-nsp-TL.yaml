model_params:
  models:
    encoder: 'FCN_Encoder'
    decoder: 'Decoder'
  transfer_learning:  # empty value means None
    encoder: [ "encoder", "../../line_OCR/ctc/outputs/LJK_RS1_200_2010_v2-nsp_ntsek/checkpoints/best_1988.pt", True, True ]
    decoder: [ "decoder", "../../line_OCR/ctc/outputs/LJK_RS1_200_2010_v2-nsp_ntsek/checkpoints/best_1988.pt", True, True ]
  input_channels: 3 # 1 for grayscale images, 3 for RGB ones (or grayscale as RGB)
  dropout: 0.5

dataset_params:
  name: 'LJK-RS1-200-2010-revised'
  dataset_class: 'OCRDataset'
#  label_file: 'labels_v2.pkl'
  config:
    width_divisor: 8  # Image width will be divided by 8
    height_divisor: 32  # Image height will be divided by 32
    padding_value: 0  # Image padding value
    padding_token: 1000  # Label padding value (None: default value is chosen)
    charset_mode: "CTC"  # add blank token
    constraints: [ "CTC_line" ]  # Padding for CTC requirements if necessary
    exclude_chars: [' '] # exclude all spaces
    preprocessings:
      [
        {
          type: "dpi",  # modify image resolution
          source: 150,  # from 300 dpi
          target: 300,  # to 150 dpi
        },
        {
          type: "to_RGB",
          # if grayscale image, produce RGB one (3 channels with same value) otherwise do nothing
        }
      ]
    # Augmentation techniques to use at training time
    augmentation: {
        dpi: {
          proba: 0.2,
          min_factor: 0.75,
          max_factor: 1.25,
        },
        perspective: {
          proba: 0.2,
          min_factor: 0,
          max_factor: 0.3,
        },
        elastic_distortion: {
          proba: 0.2,
          max_magnitude: 20,
          max_kernel: 3,
        },
        random_transform: {
          proba: 0.2,
          max_val: 16,
        },
        dilation_erosion: {
          proba: 0.2,
          min_kernel: 1,
          max_kernel: 3,
          iterations: 1,
        },
        brightness: {
          proba: 0.2,
          min_factor: 0.01,
          max_factor: 1,
        },
        "contrast": {
          proba: 0.2,
          min_factor: 0.01,
          max_factor: 1,
        },
        sign_flipping: {
          proba: 0.2,
        },
      }

training_params:
  max_nb_epochs: 1000  # max number of epochs for the training
  load_epoch: "last"  # ["best", "last"], to load weights from best epoch or last trained epoch
  interval_save_weights:   # None: keep best and last only
  use_ddp: False  # Use DistributedDataParallel
  use_apex: True  # Enable mix-precision with apex package
  batch_size: 16  # mini-batch size per GPU
  optimizer:
    class: 'Adam'
    args:
      lr: 0.0001
      amsgrad: False
  eval_on_valid: True  # Whether to eval and logs metrics on validation set during training or not
  eval_on_valid_interval: 2  # Interval (in epochs) to evaluate during training
  focus_metric: "cer"  # Metrics to focus on to determine best epoch
  expected_metric_value: "low"  # ["high", "low"] What is best for the focus metric value
  train_metrics: [ "loss_ctc", "cer", 'coer', "wer"]  # Metrics name for training
  eval_metrics: [ "loss_ctc", "cer", 'coer', "wer"]  # Metrics name for evaluation on validation set during training
  force_cpu: False  # True for debug purposes to run on cpu only
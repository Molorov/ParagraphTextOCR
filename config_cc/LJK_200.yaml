model_params:
  models:
    encoder:
      name: 'FCN_Encoder'
      dropout: 0.5
      drop_inside: True
      norm: 'in'
      kaiming_init: False
    attention:
      name: 'LocalDWConvAttention'
      attn_activation: 'softmax'
      kaiming_init: False
    decoder:
      name: 'DecoderH'
      dropout: 0.5
      pool_method: 'avg'
      kaiming_init: False
  transfer_learning:  # empty value means None
    encoder: [ "encoder", "../../document_OCR/comp_ctc/outputs/LJK_200+nosp/checkpoints/last_1999.pt", True, True ]
    attention: [ "attention", "../../document_OCR/comp_ctc/outputs/LJK_200+nosp/checkpoints/last_1999.pt", True, True ]
    decoder: [ "decoder", "../../document_OCR/comp_ctc/outputs/LJK_200+nosp/checkpoints/last_1999.pt", True, True ]
  save_ema: True
  input_channels: 3 # 1 for grayscale images, 3 for RGB ones (or grayscale as RGB)
  features_size: 256  # encoder output features maps
  comp_ctc:
    line_repeat: False
    trunc_height: False

dataset_params:
  name: 'LJK_200'
  dataset_class: 'OCRDataset'
  config:
    width_divisor: 8  # Image width will be divided by 8
    height_divisor: 32  # Image height will be divided by 32
    padding_value: 0  # Image padding value
    padding_token:   # Label padding value (None: default value is chosen)
    charset_mode: "CTC"  # add blank token
    constraints: [ "padding", "CTC_va" ]  # Padding for models constraints and CTC requirements
    exclude_chars: [' '] # exclude all spaces and syllable points
    padding:
      min_height: 480  # to handle model requirements (AdaptivePooling)
      min_width: 800  # to handle model requirements (AdaptivePooling)

    preprocessings:
      [
        {
          type: "dpi",  # modify image resolution
          source: 75,  # from 75 dpi
          target: 150,  # to 150 dpi
        },
        {
          type: "to_RGB",
          # if grayscale image, produce RGB one (3 channels with same value) otherwise do nothing
        }
      ]
    # Augmentation techniques to use at training time
    augmentation: {
        dpi: {
          proba: 0.2,
          min_factor: 0.75,
          max_factor: 1, # different from line_config(1.25)
          },
        perspective: {
          proba: 0.2,
          min_factor: 0,
          max_factor: 0.3,
        },
        elastic_distortion: {
          proba: 0.2,
          max_magnitude: 20,
          max_kernel: 3,
        },
        random_transform: {
          proba: 0.2,
          max_val: 125, # different from line_config(16)
        },
        dilation_erosion: {
          proba: 0.2,
          min_kernel: 1,
          max_kernel: 3,
          iterations: 1,
        },
        brightness: {
          proba: 0.2,
          min_factor: 0.01,
          max_factor: 1,
        },
        contrast: {
          proba: 0.2,
          min_factor: 0.01,
          max_factor: 1,
        },
        sign_flipping: {
          proba: 0.2,
        },
      }


training_params:
    max_nb_epochs: 2000  # max number of epochs for the training
    load_epoch: "last"  # ["best", "last"], to load weights from best epoch or last trained epoch
    interval_save_weights:   # None: keep best and last only
    batch_size: 2  # mini-batch size per GPU
    use_ddp: False  # Use DistributedDataParallel
    ddp_port: "10000"  # Port for Distributed Data Parallel communications
    use_apex: True  # Enable mix-precision with apex package
    optimizer:
        class: 'Adam'
        args:
          lr: 0.0001
          amsgrad: False

    eval_on_valid: True  # Whether to eval and logs metrics on validation set during training or not
    eval_on_valid_interval: 2  # Interval (in epochs) to evaluate during training
    focus_metric: "cer"  # Metrics to focus on to determine best epoch
    expected_metric_value: "low"  # ["high", "low"] What is best for the focus metric value
    train_metrics: ["loss_ctc", "cer", "wer", "coer", "diff_len"]  # Metrics name for training
    eval_metrics: ["loss_ctc", "cer", "wer", "coer", "diff_len"]  # Metrics name for evaluation on validation set during training
    force_cpu: False  # True for debug purposes to run on cpu only
    stop_mode: None